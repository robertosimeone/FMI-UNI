{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашно 1\n",
    "\n",
    "Линейна и логистична регресия.\n",
    "\n",
    "Предайте същата тетрадка като тази в заданието с нанесените от вас промени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 1\n",
    "\n",
    "В заданието  имате данните отностно сърдечни заболявания, които са взети от [това състезание в kaggle](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction).\n",
    "Данните, които трябва да прочетете, са файлът `hearth.csv`\n",
    "\n",
    "1.1 Прочетете набора от данни с помощта на `pandas`. (*hint: read_csv*)\n",
    "\n",
    "1.2 След което разбийте данните на атрибути и целеви атрибут. в случая целевия атрибут е HeartDisease.\n",
    "\n",
    "1.3 Подгответе категорийните променливи, така че да могат да бъдат обработвани като индикатори. (*hint: get_dummies*)\n",
    "\n",
    "1.4 Разбийте данните на тренировъчно и тестово множество (като 30% от данните да са в тестовото множество).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mglearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_moons, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "warnings.filterwarnings(action='ignore', module='scipy', message='^internal gelsd')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1\n",
    "heart = pd.read_csv(\"heart.csv\")\n",
    "X = heart[[\"Age\",\"Sex\",\"ChestPainType\",\"RestingBP\",\"Cholesterol\",\"FastingBS\",\"RestingECG\",\"MaxHR\",\"ExerciseAngina\",\"Oldpeak\",\"ST_Slope\"]]\n",
    "y = heart.HeartDisease\n",
    "print(heart.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2,1.3,1.4\n",
    "chest_pain_type = pd.get_dummies(X[\"ChestPainType\"])*1\n",
    "sex = pd.get_dummies(X[\"Sex\"])*1\n",
    "resting_ecg = pd.get_dummies(X[\"RestingECG\"])*1\n",
    "exercise_angina = pd.get_dummies(X[\"ExerciseAngina\"])*1\n",
    "st_slope = pd.get_dummies(X[\"ST_Slope\"])*1 \n",
    "new_X = X.drop([\"ChestPainType\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\",\"Sex\"],axis=1)\n",
    "new_X = pd.concat([new_X,chest_pain_type,sex,resting_ecg,exercise_angina,st_slope],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2\n",
    "    \n",
    "2.1 Напревете логистична регресия, като я натренирате върху тренировъчните данни. Тествайте колко добре се справя върху тренировъчните и тестовите данни, използвайки функцията `.score()`.\n",
    "\n",
    "2.2 Тествайте как ще се промени резултата като добавите по-голяма регулизация.\n",
    "\n",
    "2.3 Тествайте как ще се промени резултата като добавите по-малка регулизация. \n",
    "\n",
    "2.4 Обеснете как интерпретирате резултатите от екпериментите си."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.1\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train,y_train)\n",
    "print(\"Training score: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "print(\"Test score:     {:.2f}\\n\".format(model.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 0.1\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 2\n",
      "k : 0.2\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 3\n",
      "k : 0.3\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 4\n",
      "k : 0.4\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 5\n",
      "k : 0.5\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 6\n",
      "k : 0.6\n",
      "Training score: 0.86\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 7\n",
      "k : 0.7\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 8\n",
      "k : 0.8\n",
      "Training score: 0.86\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 9\n",
      "k : 0.9\n",
      "Training score: 0.86\n",
      "Test score:     0.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "counter = 1\n",
    "for k in range(1,10):\n",
    "    inner_k = k/10\n",
    "    model = LogisticRegression(C=inner_k,max_iter=10000).fit(X_train,y_train)\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test, y_test))) \n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 1.1\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 2\n",
      "k : 1.2\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 3\n",
      "k : 1.3\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 4\n",
      "k : 1.4\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 5\n",
      "k : 1.5\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 6\n",
      "k : 1.6\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 7\n",
      "k : 1.7\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 8\n",
      "k : 1.8\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 9\n",
      "k : 1.9\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 10\n",
      "k : 2.0\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 11\n",
      "k : 2.1\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 12\n",
      "k : 2.2\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 13\n",
      "k : 2.3\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 14\n",
      "k : 2.4\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 15\n",
      "k : 2.5\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 16\n",
      "k : 2.6\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 17\n",
      "k : 2.7\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 18\n",
      "k : 2.8\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 19\n",
      "k : 2.9\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 20\n",
      "k : 3.0\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 21\n",
      "k : 3.1\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 22\n",
      "k : 3.2\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 23\n",
      "k : 3.3\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 24\n",
      "k : 3.4\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 25\n",
      "k : 3.5\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 26\n",
      "k : 3.6\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 27\n",
      "k : 3.7\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 28\n",
      "k : 3.8\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 29\n",
      "k : 3.9\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 30\n",
      "k : 4.0\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 31\n",
      "k : 4.1\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 32\n",
      "k : 4.2\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 33\n",
      "k : 4.3\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 34\n",
      "k : 4.4\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 35\n",
      "k : 4.5\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 36\n",
      "k : 4.6\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 37\n",
      "k : 4.7\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 38\n",
      "k : 4.8\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 39\n",
      "k : 4.9\n",
      "Training score: 0.86\n",
      "Test score:     0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.3\n",
    "counter = 1\n",
    "for k in range(11,50):\n",
    "    inner_k = k/10\n",
    "    model = LogisticRegression(C=inner_k,max_iter=10000).fit(X_train,y_train)\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test, y_test))) \n",
    "    counter +=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.4\n",
    "При по-голяма регуляризация получаваме най-добър резултат при `C = 0.6`,`C = 0.8` и `C = 0.9` с `train_score = 0.86` и `test_score = 0.89`. При по-малка регуляризация не получаваме никакво подобрение.Имаме добра генерализация - нямаме нито underfitting, нито overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 3\n",
    "\n",
    "3.1 Създайте модел за квадратични характеристики (`степен = 2`). Използвайте PolynomialFeatures, за да създадете данните.\n",
    "\n",
    "3.2 Повторете стъпките от Задача 2 върху квадратичните данни.\n",
    "\n",
    "3.3 Намерете броя на атрибутите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "poly_features = PolynomialFeatures(2)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.2.1\n",
    "model = LogisticRegression(solver='liblinear',max_iter=10000).fit(X_train_poly,y_train)\n",
    "print(\"Training score: {:.2f}\".format(model.score(X_train_poly, y_train)))\n",
    "print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 0.1\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 2\n",
      "k : 0.2\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 3\n",
      "k : 0.3\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 4\n",
      "k : 0.4\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 5\n",
      "k : 0.5\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 6\n",
      "k : 0.6\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 7\n",
      "k : 0.7\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 8\n",
      "k : 0.8\n",
      "Training score: 0.89\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 9\n",
      "k : 0.9\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.2.2\n",
    "counter = 1\n",
    "poly_features = PolynomialFeatures(2)\n",
    "for k in range(1,10):\n",
    "    inner_k = k/10\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    model = LogisticRegression(solver='liblinear',C=inner_k,max_iter=10000).fit(X_train_poly,y_train)\n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train_poly, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_poly, y_test)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 1.1\n",
      "Training score: 0.90\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 2\n",
      "k : 1.2\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 3\n",
      "k : 1.3\n",
      "Training score: 0.90\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 4\n",
      "k : 1.4\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 5\n",
      "k : 1.5\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 6\n",
      "k : 1.6\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 7\n",
      "k : 1.7\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 8\n",
      "k : 1.8\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 9\n",
      "k : 1.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 10\n",
      "k : 2.0\n",
      "Training score: 0.91\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 11\n",
      "k : 2.1\n",
      "Training score: 0.91\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 12\n",
      "k : 2.2\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 13\n",
      "k : 2.3\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 14\n",
      "k : 2.4\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 15\n",
      "k : 2.5\n",
      "Training score: 0.91\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 16\n",
      "k : 2.6\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 17\n",
      "k : 2.7\n",
      "Training score: 0.90\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 18\n",
      "k : 2.8\n",
      "Training score: 0.91\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 19\n",
      "k : 2.9\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 20\n",
      "k : 3.0\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 21\n",
      "k : 3.1\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 22\n",
      "k : 3.2\n",
      "Training score: 0.91\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 23\n",
      "k : 3.3\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 24\n",
      "k : 3.4\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 25\n",
      "k : 3.5\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 26\n",
      "k : 3.6\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 27\n",
      "k : 3.7\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 28\n",
      "k : 3.8\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 29\n",
      "k : 3.9\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 30\n",
      "k : 4.0\n",
      "Training score: 0.89\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 31\n",
      "k : 4.1\n",
      "Training score: 0.91\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 32\n",
      "k : 4.2\n",
      "Training score: 0.91\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 33\n",
      "k : 4.3\n",
      "Training score: 0.89\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 34\n",
      "k : 4.4\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 35\n",
      "k : 4.5\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 36\n",
      "k : 4.6\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 37\n",
      "k : 4.7\n",
      "Training score: 0.90\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 38\n",
      "k : 4.8\n",
      "Training score: 0.91\n",
      "Test score:     0.87\n",
      "\n",
      "Test number 39\n",
      "k : 4.9\n",
      "Training score: 0.90\n",
      "Test score:     0.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.2.3\n",
    "counter = 1\n",
    "for k in range(11,50):\n",
    "    inner_k = k/10\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    model = LogisticRegression(solver='liblinear',C=inner_k,max_iter=10000).fit(X_train_poly,y_train)\n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train_poly, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_poly, y_test)))\n",
    "    counter +=1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3.2.4\n",
    "При по-голяма регуляризация получаваме най-добър резултат при `C = 0.3`,`C = 0.4` и т.н. с `train_score = 0.90` и `test_score = 0.89`,като изследваме регуляризацията от 0.1 до 0.9 с стъпка 0.1. При по-малка регуляризация имаме повишаване в `train_score`, но това увеличение идва с намаление в `test_score`.Най-добрия резултат при по-малка регуляризация е `train_score = 91` и `test_score = 88`, при `C = 2,5` и `C = 3.2` и т.н.,като изследваме регуляризацията от 1.1 до 4.9 със стъпка 0.1.Получаме добра генерализация - както и в задача 2, нямаме нито underfitting, нито overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "#3.3\n",
    "print(X_train_poly.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 4\n",
    "\n",
    "Повторете стъпките от задача 3 като преди това скалирате данните между 0 и 1. Сравнете резултата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.2.1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(poly_features.fit_transform(X_train))\n",
    "X_test_scaled = scaler.transform(poly_features.fit_transform(X_test))\n",
    "model = LogisticRegression(solver='liblinear',max_iter=10000).fit(X_train_scaled,y_train)\n",
    "print(\"Training score: {:.2f}\".format(model.score(X_train_scaled, y_train)))\n",
    "print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_scaled, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 0.1\n",
      "Training score: 0.87\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 2\n",
      "k : 0.2\n",
      "Training score: 0.87\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 3\n",
      "k : 0.3\n",
      "Training score: 0.87\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 4\n",
      "k : 0.4\n",
      "Training score: 0.88\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 5\n",
      "k : 0.5\n",
      "Training score: 0.88\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 6\n",
      "k : 0.6\n",
      "Training score: 0.88\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 7\n",
      "k : 0.7\n",
      "Training score: 0.88\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 8\n",
      "k : 0.8\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 9\n",
      "k : 0.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.2.2\n",
    "counter = 1\n",
    "for k in range(1,10):\n",
    "    inner_k = k/10\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    model = LogisticRegression(solver='liblinear',C=inner_k,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train_scaled, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_scaled, y_test)))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test number 1\n",
      "k : 1.1\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 2\n",
      "k : 1.2\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 3\n",
      "k : 1.3\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 4\n",
      "k : 1.4\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 5\n",
      "k : 1.5\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 6\n",
      "k : 1.6\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 7\n",
      "k : 1.7\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 8\n",
      "k : 1.8\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 9\n",
      "k : 1.9\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 10\n",
      "k : 2.0\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 11\n",
      "k : 2.1\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 12\n",
      "k : 2.2\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 13\n",
      "k : 2.3\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 14\n",
      "k : 2.4\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 15\n",
      "k : 2.5\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 16\n",
      "k : 2.6\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 17\n",
      "k : 2.7\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 18\n",
      "k : 2.8\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 19\n",
      "k : 2.9\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 20\n",
      "k : 3.0\n",
      "Training score: 0.89\n",
      "Test score:     0.91\n",
      "\n",
      "Test number 21\n",
      "k : 3.1\n",
      "Training score: 0.89\n",
      "Test score:     0.91\n",
      "\n",
      "Test number 22\n",
      "k : 3.2\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 23\n",
      "k : 3.3\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 24\n",
      "k : 3.4\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 25\n",
      "k : 3.5\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 26\n",
      "k : 3.6\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 27\n",
      "k : 3.7\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 28\n",
      "k : 3.8\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 29\n",
      "k : 3.9\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 30\n",
      "k : 4.0\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 31\n",
      "k : 4.1\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 32\n",
      "k : 4.2\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 33\n",
      "k : 4.3\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 34\n",
      "k : 4.4\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 35\n",
      "k : 4.5\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 36\n",
      "k : 4.6\n",
      "Training score: 0.89\n",
      "Test score:     0.90\n",
      "\n",
      "Test number 37\n",
      "k : 4.7\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 38\n",
      "k : 4.8\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 39\n",
      "k : 4.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 40\n",
      "k : 5.0\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 41\n",
      "k : 5.1\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 42\n",
      "k : 5.2\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 43\n",
      "k : 5.3\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 44\n",
      "k : 5.4\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 45\n",
      "k : 5.5\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 46\n",
      "k : 5.6\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 47\n",
      "k : 5.7\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 48\n",
      "k : 5.8\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 49\n",
      "k : 5.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 50\n",
      "k : 6.0\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 51\n",
      "k : 6.1\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 52\n",
      "k : 6.2\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 53\n",
      "k : 6.3\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 54\n",
      "k : 6.4\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 55\n",
      "k : 6.5\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 56\n",
      "k : 6.6\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 57\n",
      "k : 6.7\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 58\n",
      "k : 6.8\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 59\n",
      "k : 6.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 60\n",
      "k : 7.0\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 61\n",
      "k : 7.1\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 62\n",
      "k : 7.2\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 63\n",
      "k : 7.3\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 64\n",
      "k : 7.4\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 65\n",
      "k : 7.5\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 66\n",
      "k : 7.6\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 67\n",
      "k : 7.7\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 68\n",
      "k : 7.8\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 69\n",
      "k : 7.9\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 70\n",
      "k : 8.0\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 71\n",
      "k : 8.1\n",
      "Training score: 0.89\n",
      "Test score:     0.89\n",
      "\n",
      "Test number 72\n",
      "k : 8.2\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 73\n",
      "k : 8.3\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 74\n",
      "k : 8.4\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 75\n",
      "k : 8.5\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 76\n",
      "k : 8.6\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 77\n",
      "k : 8.7\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 78\n",
      "k : 8.8\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 79\n",
      "k : 8.9\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 80\n",
      "k : 9.0\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 81\n",
      "k : 9.1\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 82\n",
      "k : 9.2\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 83\n",
      "k : 9.3\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 84\n",
      "k : 9.4\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 85\n",
      "k : 9.5\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 86\n",
      "k : 9.6\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 87\n",
      "k : 9.7\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 88\n",
      "k : 9.8\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n",
      "Test number 89\n",
      "k : 9.9\n",
      "Training score: 0.89\n",
      "Test score:     0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4.2.3\n",
    "counter = 1\n",
    "for k in range(11,100):\n",
    "    inner_k = k/10\n",
    "    print(\"Test number {}\".format(counter))\n",
    "    print(\"k : {}\".format(inner_k)) \n",
    "    model = LogisticRegression(solver='liblinear',C=inner_k,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print(\"Training score: {:.2f}\".format(model.score(X_train_scaled, y_train)))\n",
    "    print(\"Test score:     {:.2f}\\n\".format(model.score(X_test_scaled, y_test)))\n",
    "    counter +=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4.2.4\n",
    "При по-голяма регуляризация получаваме най-добър резултат при `C = 0.8`,`C = 0.9` и т.н. с `train_score = 0.89` и `test_score = 0.91`,като изследваме регуляризацията от 0.1 до 0.9 с стъпка 0.1.При по-малка регуляризация, достигаме до същите максимуми за стойностите на `C = 1.1` и `C = 1`.Тук можем да забележим малко увеличение във тестовия резултат за сметка на тренировъчния.Отново имаме добра генерализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "#4.3.3\n",
    "print(X_train_scaled.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
